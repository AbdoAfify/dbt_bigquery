# dbt_bigquery

End-to-end dbt data pipeline project using BigQuery to model and analyze sales data. Includes raw ingestion, staging, transformation layers, and documentation.

# Sales Analytics with dbt & BigQuery

This project demonstrates a full-stack modern data pipeline using **dbt (Data Build Tool)** and **Google BigQuery** to transform and analyze sales data.

---

## ğŸš€ Project Overview

This repository contains a sales analytics pipeline built using **dbt** on **BigQuery**, following a modular approach:

- **Raw Layer**: Ingests randomly generated sales data
- **Staging Layer**: Cleans, formats, and prepares raw data
- **Mart Layer**: Aggregates metrics such as revenue and order count
- **Macros**: Reusable logic for dynamic partitioning
- **Tests & Documentation**: Data quality checks and auto-generated docs with `dbt docs`

---

## ğŸ“Š Tech Stack

- [dbt](https://www.getdbt.com/)
- [Google BigQuery](https://cloud.google.com/bigquery)
- [Google Cloud SDK](https://cloud.google.com/sdk)
- SQL (BigQuery Standard SQL)
- Jinja2 (for macros)

---

## ğŸ“ Project Structure

```text
sales_analytics/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ staging/                 # Cleans and prepares raw data
â”‚   â”‚   â””â”€â”€ stage_sales.sql      # Transforms raw sales into a clean format
â”‚   â”œâ”€â”€ example/
â”‚   â”‚   â””â”€â”€ Mart/
â”‚   â”‚       â””â”€â”€ sales_final.sql  # Aggregates metrics like revenue, orders
â”‚
â”œâ”€â”€ macros/                      # Custom reusable Jinja macros
â”‚   â””â”€â”€ dynamic_partition.sql    # Macro for recent/historical partitioning
â”‚
â”œâ”€â”€ tests/                       # dbt schema tests
â”‚   â””â”€â”€ schema.yml               # Column-level tests and model documentation
â”‚
â”œâ”€â”€ dbt_project.yml              # Main dbt project config
â”œâ”€â”€ profiles.yml (local)         # User-specific connection settings (not committed)
â”œâ”€â”€ README.md                    # Project documentation
â””â”€â”€ target/                      # Compiled SQL and docs (auto-generated)
âœ… Key Features
ğŸ” Modular SQL modeling: Raw â†’ Staging â†’ Mart layers

ğŸ§  Dynamic macros: Partition rows into recent or historical buckets

ğŸ§ª Data testing: Not-null tests for key columns (defined in schema.yml)

ğŸ“š Auto documentation: Interactive lineage and metadata with dbt docs

ğŸ” OAuth-secured connection to BigQuery

âš™ï¸ Setup Instructions
Prerequisites
Python 3.9+

dbt CLI (pip install dbt-bigquery)

Google Cloud SDK

BigQuery access (with project & dataset ready)

Steps
bash
Copy
Edit
# Authenticate with GCP
gcloud auth application-default login

# Install dependencies
pip install dbt-bigquery

# Initialize dbt
dbt debug
dbt compile
dbt run

# Run tests (uses schema.yml definitions)
dbt test

# Generate docs (uses schema.yml metadata)
dbt docs generate
dbt docs serve
